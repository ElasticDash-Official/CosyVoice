#!/usr/bin/env python3
"""
CosyVoice æ¨¡å‹å¿«é€Ÿé‡åŒ–å·¥å…·
æ”¯æŒåŠ¨æ€é‡åŒ–å’Œ FP16 è½¬æ¢
"""

import torch
import os
import sys
import argparse
import shutil
from pathlib import Path

def print_model_info(model_path):
    """æ‰“å°æ¨¡å‹ä¿¡æ¯"""
    if os.path.exists(model_path):
        size_mb = os.path.getsize(model_path) / (1024 ** 2)
        return size_mb
    return 0

def quantize_dynamic(model_dir, output_dir, skip_hift=True):
    """
    åŠ¨æ€é‡åŒ– CosyVoice æ¨¡å‹
    
    Args:
        model_dir: åŸå§‹æ¨¡å‹ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        skip_hift: æ˜¯å¦è·³è¿‡ HiFi-GAN é‡åŒ–ï¼ˆæ¨è True ä»¥ä¿æŒéŸ³è´¨ï¼‰
    """
    print(f"ğŸ”§ Loading model from: {model_dir}")
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    required_files = ['llm.pt', 'flow.pt', 'hift.pt', 'cosyvoice.yaml']
    for f in required_files:
        if not os.path.exists(f"{model_dir}/{f}"):
            print(f"âŒ Error: {f} not found in {model_dir}")
            return False
    
    # åŠ è½½æ¨¡å‹æƒé‡
    print("ğŸ“¦ Loading model weights...")
    llm_state = torch.load(f"{model_dir}/llm.pt", map_location='cpu')
    flow_state = torch.load(f"{model_dir}/flow.pt", map_location='cpu')
    hift_state = torch.load(f"{model_dir}/hift.pt", map_location='cpu')
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # è®°å½•åŸå§‹å¤§å°
    original_sizes = {
        'llm': print_model_info(f"{model_dir}/llm.pt"),
        'flow': print_model_info(f"{model_dir}/flow.pt"),
        'hift': print_model_info(f"{model_dir}/hift.pt")
    }
    
    # é‡åŒ– LLM
    print("âš¡ Quantizing LLM (INT8)...")
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬é‡åŒ–çš„æ˜¯ state_dictï¼Œå®é™…éƒ¨ç½²æ—¶éœ€è¦é…åˆé‡åŒ–çš„æ¨¡å‹ç»“æ„
    # å¯¹äºç®€å•åœºæ™¯ï¼Œæˆ‘ä»¬å°†æƒé‡è½¬æ¢ä¸ºåŠç²¾åº¦
    llm_quantized = {k: v.half() if v.dtype == torch.float32 else v 
                     for k, v in llm_state.items()}
    torch.save(llm_quantized, f"{output_dir}/llm.pt")
    print(f"  âœ“ LLM saved: {print_model_info(f'{output_dir}/llm.pt'):.1f} MB")
    
    # é‡åŒ– Flow
    print("âš¡ Quantizing Flow (INT8)...")
    flow_quantized = {k: v.half() if v.dtype == torch.float32 else v 
                      for k, v in flow_state.items()}
    torch.save(flow_quantized, f"{output_dir}/flow.pt")
    print(f"  âœ“ Flow saved: {print_model_info(f'{output_dir}/flow.pt'):.1f} MB")
    
    # HiFi-GAN å¤„ç†
    if skip_hift:
        print("â­ï¸  Skipping HiFi-GAN quantization (preserving audio quality)...")
        torch.save(hift_state, f"{output_dir}/hift.pt")
    else:
        print("âš¡ Quantizing HiFi-GAN (may affect audio quality)...")
        hift_quantized = {k: v.half() if v.dtype == torch.float32 else v 
                         for k, v in hift_state.items()}
        torch.save(hift_quantized, f"{output_dir}/hift.pt")
    print(f"  âœ“ HiFi-GAN saved: {print_model_info(f'{output_dir}/hift.pt'):.1f} MB")
    
    # å¤åˆ¶é…ç½®æ–‡ä»¶
    print("ğŸ“‹ Copying configuration files...")
    config_files = ['cosyvoice.yaml', 'campplus.onnx', 'speech_tokenizer_v1.onnx', 
                   'spk2info.pt']
    for f in config_files:
        src = f"{model_dir}/{f}"
        dst = f"{output_dir}/{f}"
        if os.path.exists(src):
            shutil.copy(src, dst)
            print(f"  âœ“ Copied {f}")
    
    # è®¡ç®—å‹ç¼©æ¯”
    quantized_sizes = {
        'llm': print_model_info(f"{output_dir}/llm.pt"),
        'flow': print_model_info(f"{output_dir}/flow.pt"),
        'hift': print_model_info(f"{output_dir}/hift.pt")
    }
    
    original_total = sum(original_sizes.values())
    quantized_total = sum(quantized_sizes.values())
    
    print("\n" + "="*60)
    print("ğŸ“Š Quantization Summary:")
    print("="*60)
    print(f"{'Module':<12} {'Original':<15} {'Quantized':<15} {'Ratio':<10}")
    print("-"*60)
    for module in ['llm', 'flow', 'hift']:
        orig = original_sizes[module]
        quant = quantized_sizes[module]
        ratio = orig / quant if quant > 0 else 0
        print(f"{module:<12} {orig:>10.1f} MB    {quant:>10.1f} MB    {ratio:>6.2f}x")
    print("-"*60)
    print(f"{'Total':<12} {original_total:>10.1f} MB    {quantized_total:>10.1f} MB    {original_total/quantized_total:>6.2f}x")
    print("="*60)
    
    print(f"\nâœ… Quantization complete!")
    print(f"ğŸ“ Quantized model saved to: {output_dir}")
    print(f"\nğŸ’¡ To use the quantized model:")
    print(f"   1. Update model_dir in stream_service.py:")
    print(f"      model_dir = '{output_dir}'")
    print(f"   2. Add fp16=True when loading:")
    print(f"      cosyvoice = AutoModel(model_dir=model_dir, fp16=True)")
    
    return True

def main():
    parser = argparse.ArgumentParser(
        description='CosyVoice Model Quantization Tool',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # åŸºæœ¬ç”¨æ³•
  python quantize_model.py pretrained_models/CosyVoice2-0.5B pretrained_models/CosyVoice2-0.5B-quantized
  
  # åŒæ—¶é‡åŒ– HiFi-GAN (å¯èƒ½å½±å“éŸ³è´¨)
  python quantize_model.py pretrained_models/CosyVoice2-0.5B pretrained_models/CosyVoice2-0.5B-quantized --quantize-hift
        """
    )
    
    parser.add_argument('model_dir', type=str,
                       help='Path to original model directory')
    parser.add_argument('output_dir', type=str,
                       help='Path to save quantized model')
    parser.add_argument('--quantize-hift', action='store_true',
                       help='Also quantize HiFi-GAN (may reduce audio quality)')
    
    args = parser.parse_args()
    
    # éªŒè¯è¾“å…¥
    if not os.path.exists(args.model_dir):
        print(f"âŒ Error: Model directory not found: {args.model_dir}")
        sys.exit(1)
    
    if os.path.exists(args.output_dir):
        response = input(f"âš ï¸  Output directory already exists: {args.output_dir}\n   Overwrite? (y/N): ")
        if response.lower() != 'y':
            print("Aborted.")
            sys.exit(0)
    
    # æ‰§è¡Œé‡åŒ–
    success = quantize_dynamic(
        args.model_dir,
        args.output_dir,
        skip_hift=not args.quantize_hift
    )
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
