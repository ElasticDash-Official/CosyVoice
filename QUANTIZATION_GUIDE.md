# CosyVoice æ¨¡å‹é‡åŒ–å®Œæ•´æŒ‡å—

## ä»€ä¹ˆæ˜¯æ¨¡å‹é‡åŒ–ï¼Ÿ

æ¨¡å‹é‡åŒ–æ˜¯å°†æ¨¡å‹å‚æ•°ä» **32ä½æµ®ç‚¹æ•° (FP32)** è½¬æ¢ä¸º **8ä½æ•´æ•° (INT8)** æˆ– **16ä½æµ®ç‚¹æ•° (FP16)**ï¼Œä»è€Œï¼š
- âš¡ **æ¨ç†é€Ÿåº¦æå‡ 2-4å€**
- ğŸ’¾ **æ¨¡å‹å¤§å°å‡å°‘ 2-4å€**
- ğŸ¯ **ç²¾åº¦æŸå¤± < 5%**ï¼ˆé€šå¸¸å¯å¿½ç•¥ï¼‰

## é‡åŒ–æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | é€Ÿåº¦æå‡ | ç²¾åº¦æŸå¤± | éš¾åº¦ | æ¨èåœºæ™¯ |
|-----|---------|---------|------|---------|
| **FP16 åŠç²¾åº¦** | 1.5-2x | <1% | â­ ç®€å• | GPUæ¨ç†ï¼Œå‡ ä¹æ— æŸ |
| **åŠ¨æ€é‡åŒ–** | 2-3x | 2-3% | â­â­ ä¸­ç­‰ | CPU/GPUï¼Œå¿«é€Ÿéƒ¨ç½² |
| **é™æ€é‡åŒ–** | 3-4x | 1-2% | â­â­â­ å¤æ‚ | ç”Ÿäº§ç¯å¢ƒï¼Œéœ€æ ¡å‡† |
| **é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ(QAT)** | 3-4x | <1% | â­â­â­â­ å›°éš¾ | æœ€ä½³è´¨é‡ï¼Œéœ€é‡è®­ç»ƒ |

## æ–¹æ³• 1: FP16 åŠç²¾åº¦ï¼ˆæœ€ç®€å•ï¼Œæ¨èï¼‰

### ä¼˜ç‚¹
- âœ… å‡ ä¹æ— ç²¾åº¦æŸå¤±
- âœ… é€Ÿåº¦æå‡ 50-100%
- âœ… åªéœ€ä¿®æ”¹å‡ è¡Œä»£ç 
- âœ… æ”¯æŒ NVIDIA GPU (Compute Capability >= 7.0)

### ä½¿ç”¨æ–¹æ³•

**åœ¨ `stream_service.py` ä¸­å¯ç”¨ FP16ï¼š**

```python
# ä¿®æ”¹æ¨¡å‹åˆå§‹åŒ–
model_dir = "/home/ec2-user/CosyVoice/pretrained_models/Fun-CosyVoice3-0.5B-2512"
cosyvoice = AutoModel(model_dir=model_dir, fp16=True)  # æ·»åŠ  fp16=True
```

**æˆ–ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼š**
```bash
export COSYVOICE_FP16=1
python stream_service.py
```

### éªŒè¯ FP16 æ˜¯å¦ç”Ÿæ•ˆ
```python
# æ£€æŸ¥æ¨¡å‹å‚æ•°ç±»å‹
print(next(cosyvoice.model.llm.parameters()).dtype)
# è¾“å‡º: torch.float16 (æˆåŠŸ) æˆ– torch.float32 (æœªå¯ç”¨)
```

---

## æ–¹æ³• 2: åŠ¨æ€é‡åŒ–ï¼ˆæ¨èï¼Œå¹³è¡¡æ€§èƒ½å’Œè´¨é‡ï¼‰

### ç‰¹ç‚¹
- è¿è¡Œæ—¶è‡ªåŠ¨é‡åŒ–æƒé‡
- ä¸éœ€è¦æ ¡å‡†æ•°æ®
- é€‚ç”¨äº Linear å±‚ï¼ˆå…¨è¿æ¥å±‚ï¼‰

### ä½¿ç”¨è„šæœ¬

åˆ›å»º `quantize_model.py`ï¼š

```python
import torch
from cosyvoice.cli.cosyvoice import AutoModel
import os

def quantize_dynamic(model_dir, output_dir):
    """åŠ¨æ€é‡åŒ– CosyVoice æ¨¡å‹"""
    print(f"Loading model from {model_dir}...")
    cosyvoice = AutoModel(model_dir=model_dir)
    
    os.makedirs(output_dir, exist_ok=True)
    
    # é‡åŒ– LLM æ¨¡å—
    print("Quantizing LLM...")
    llm_quantized = torch.quantization.quantize_dynamic(
        cosyvoice.model.llm,
        {torch.nn.Linear, torch.nn.LSTM, torch.nn.GRU},  # è¦é‡åŒ–çš„å±‚ç±»å‹
        dtype=torch.qint8
    )
    
    # é‡åŒ– Flow æ¨¡å—
    print("Quantizing Flow...")
    flow_quantized = torch.quantization.quantize_dynamic(
        cosyvoice.model.flow,
        {torch.nn.Linear},
        dtype=torch.qint8
    )
    
    # ä¿å­˜é‡åŒ–æ¨¡å‹
    print(f"Saving quantized models to {output_dir}...")
    torch.save(llm_quantized.state_dict(), f"{output_dir}/llm_quantized.pt")
    torch.save(flow_quantized.state_dict(), f"{output_dir}/flow_quantized.pt")
    
    # HiFi-GAN é€šå¸¸ä¸é‡åŒ–ï¼ˆå¯¹éŸ³è´¨å½±å“å¤§ï¼‰
    torch.save(cosyvoice.model.hift.state_dict(), f"{output_dir}/hift.pt")
    
    # å¤åˆ¶å…¶ä»–å¿…è¦æ–‡ä»¶
    import shutil
    for file in ['cosyvoice.yaml', 'campplus.onnx', 'speech_tokenizer_v1.onnx', 'spk2info.pt']:
        src = f"{model_dir}/{file}"
        if os.path.exists(src):
            shutil.copy(src, f"{output_dir}/{file}")
    
    print("âœ… Quantization complete!")
    print(f"Quantized model saved to: {output_dir}")
    
    # è®¡ç®—æ¨¡å‹å¤§å°
    original_size = sum(os.path.getsize(f"{model_dir}/{f}") 
                       for f in ['llm.pt', 'flow.pt', 'hift.pt'])
    quantized_size = sum(os.path.getsize(f"{output_dir}/{f}") 
                        for f in ['llm_quantized.pt', 'flow_quantized.pt', 'hift.pt'])
    
    print(f"\nğŸ“Š Size comparison:")
    print(f"  Original: {original_size / 1024**2:.1f} MB")
    print(f"  Quantized: {quantized_size / 1024**2:.1f} MB")
    print(f"  Compression: {original_size / quantized_size:.2f}x")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 3:
        print("Usage: python quantize_model.py <model_dir> <output_dir>")
        print("Example: python quantize_model.py pretrained_models/CosyVoice2-0.5B pretrained_models/CosyVoice2-0.5B-quantized")
        sys.exit(1)
    
    model_dir = sys.argv[1]
    output_dir = sys.argv[2]
    
    quantize_dynamic(model_dir, output_dir)
```

### è¿è¡Œé‡åŒ–
```bash
python quantize_model.py \
    /home/ec2-user/CosyVoice/pretrained_models/Fun-CosyVoice3-0.5B-2512 \
    /home/ec2-user/CosyVoice/pretrained_models/Fun-CosyVoice3-0.5B-2512-quantized
```

---

## æ–¹æ³• 3: é™æ€é‡åŒ–ï¼ˆæœ€ä½³æ€§èƒ½ï¼‰

### ç‰¹ç‚¹
- éœ€è¦æ ¡å‡†æ•°æ®é›†
- é‡åŒ–æ¿€æ´»å€¼å’Œæƒé‡
- æ€§èƒ½æå‡æœ€å¤§

### å®Œæ•´è„šæœ¬

åˆ›å»º `quantize_static.py`ï¼š

```python
import torch
from torch.quantization import quantize_fx
from cosyvoice.cli.cosyvoice import AutoModel
import os

def calibrate_model(model, calibration_data):
    """ä½¿ç”¨æ ¡å‡†æ•°æ®é›†"""
    model.eval()
    with torch.no_grad():
        for text, prompt_text, prompt_wav in calibration_data:
            # è¿è¡Œæ¨ç†è¿›è¡Œæ ¡å‡†
            for _ in model.inference_zero_shot(text, prompt_text, prompt_wav, stream=False):
                pass

def quantize_static(model_dir, output_dir, calibration_texts):
    """é™æ€é‡åŒ–"""
    print(f"Loading model from {model_dir}...")
    cosyvoice = AutoModel(model_dir=model_dir)
    
    # å‡†å¤‡æ ¡å‡†æ•°æ®
    print("Preparing calibration data...")
    calibration_data = []
    prompt_wav = f"{model_dir}/../asset/zero_shot_prompt.wav"
    prompt_text = "å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚"
    
    for text in calibration_texts:
        calibration_data.append((text, prompt_text, prompt_wav))
    
    # é…ç½®é‡åŒ–
    qconfig = torch.quantization.get_default_qconfig('fbgemm')
    
    # å‡†å¤‡æ¨¡å‹
    cosyvoice.model.llm.qconfig = qconfig
    cosyvoice.model.flow.qconfig = qconfig
    
    # æ’å…¥è§‚å¯Ÿå™¨
    print("Inserting observers...")
    torch.quantization.prepare(cosyvoice.model.llm, inplace=True)
    torch.quantization.prepare(cosyvoice.model.flow, inplace=True)
    
    # æ ¡å‡†
    print("Calibrating with sample data...")
    calibrate_model(cosyvoice, calibration_data)
    
    # è½¬æ¢ä¸ºé‡åŒ–æ¨¡å‹
    print("Converting to quantized model...")
    torch.quantization.convert(cosyvoice.model.llm, inplace=True)
    torch.quantization.convert(cosyvoice.model.flow, inplace=True)
    
    # ä¿å­˜
    os.makedirs(output_dir, exist_ok=True)
    torch.save(cosyvoice.model.llm.state_dict(), f"{output_dir}/llm_static_quantized.pt")
    torch.save(cosyvoice.model.flow.state_dict(), f"{output_dir}/flow_static_quantized.pt")
    
    print(f"âœ… Static quantization complete! Saved to {output_dir}")

if __name__ == "__main__":
    model_dir = "/home/ec2-user/CosyVoice/pretrained_models/Fun-CosyVoice3-0.5B-2512"
    output_dir = f"{model_dir}-static-quantized"
    
    # æ ¡å‡†æ–‡æœ¬ï¼ˆä½¿ç”¨çœŸå®åœºæ™¯çš„æ–‡æœ¬ï¼‰
    calibration_texts = [
        "ä½ å¥½ï¼Œæ¬¢è¿å…‰ä¸´æˆ‘ä»¬çš„é¤å…ã€‚",
        "ä»Šå¤©æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ",
        "è¿™æ˜¯æ‚¨çš„è´¦å•ï¼Œæ€»å…±æ˜¯ä¸€ç™¾äºŒåå…ƒã€‚",
        "ç¥æ‚¨ç”¨é¤æ„‰å¿«ï¼ŒæœŸå¾…æ‚¨çš„å†æ¬¡å…‰ä¸´ã€‚",
        "æˆ‘ä»¬ä»Šå¤©çš„ç‰¹è‰²èœæ˜¯çº¢çƒ§ç‹®å­å¤´å’Œæ¸…è’¸é²ˆé±¼ã€‚"
    ]
    
    quantize_static(model_dir, output_dir, calibration_texts)
```

---

## æ–¹æ³• 4: ä½¿ç”¨ BetterTransformer (å¿«é€Ÿä¼˜åŒ–)

### ç‰¹ç‚¹
- ä½¿ç”¨ PyTorch å†…ç½®ä¼˜åŒ–
- æ— éœ€é‡åŒ–ï¼Œé€Ÿåº¦æå‡ 20-40%
- é›¶ç²¾åº¦æŸå¤±

```python
# å®‰è£…
pip install optimum

# åœ¨ä»£ç ä¸­ä½¿ç”¨
from optimum.bettertransformer import BetterTransformer

# ä¼˜åŒ– Transformer æ¨¡å—
if hasattr(cosyvoice.model.llm, 'text_encoder'):
    cosyvoice.model.llm.text_encoder = BetterTransformer.transform(
        cosyvoice.model.llm.text_encoder
    )
```

---

## åŠ è½½é‡åŒ–æ¨¡å‹

ä¿®æ”¹ `stream_service.py` ä»¥æ”¯æŒé‡åŒ–æ¨¡å‹ï¼š

```python
import torch

# åœ¨æ¨¡å‹åˆå§‹åŒ–æ—¶
model_dir = "/home/ec2-user/CosyVoice/pretrained_models/Fun-CosyVoice3-0.5B-2512-quantized"

# æ–¹æ³•1: ç›´æ¥åŠ è½½é‡åŒ–æ¨¡å‹
cosyvoice = AutoModel(model_dir=model_dir)

# æ–¹æ³•2: æ‰‹åŠ¨åŠ è½½é‡åŒ–æƒé‡
cosyvoice = AutoModel(model_dir=original_model_dir)
quantized_llm = torch.load(f"{model_dir}/llm_quantized.pt")
quantized_flow = torch.load(f"{model_dir}/flow_quantized.pt")
cosyvoice.model.llm.load_state_dict(quantized_llm)
cosyvoice.model.flow.load_state_dict(quantized_flow)
```

---

## æ€§èƒ½æµ‹è¯•

### æµ‹è¯•è„šæœ¬ `benchmark_quantized.py`
```python
import torch
import time
from cosyvoice.cli.cosyvoice import AutoModel

def benchmark(model_dir, text, iterations=10):
    cosyvoice = AutoModel(model_dir=model_dir)
    prompt_wav = "/home/ec2-user/CosyVoice/asset/zero_shot_prompt.wav"
    prompt_text = "å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚"
    
    # é¢„çƒ­
    for _ in cosyvoice.inference_zero_shot(text, prompt_text, prompt_wav, stream=False):
        pass
    
    # æµ‹è¯•
    times = []
    for i in range(iterations):
        start = time.time()
        for _ in cosyvoice.inference_zero_shot(text, prompt_text, prompt_wav, stream=False):
            pass
        times.append(time.time() - start)
    
    avg_time = sum(times) / len(times)
    print(f"Average time: {avg_time:.3f}s")
    return avg_time

if __name__ == "__main__":
    test_text = "ä½ å¥½ï¼Œæ¬¢è¿æ¥åˆ°æˆ‘ä»¬çš„é¤å…ï¼Œä»Šå¤©æƒ³åƒç‚¹ä»€ä¹ˆå‘¢ï¼Ÿ"
    
    print("Testing original model...")
    time_original = benchmark("pretrained_models/original", test_text)
    
    print("\nTesting quantized model...")
    time_quantized = benchmark("pretrained_models/quantized", test_text)
    
    print(f"\nğŸš€ Speedup: {time_original/time_quantized:.2f}x")
```

---

## æ³¨æ„äº‹é¡¹

### âš ï¸ ä¸è¦é‡åŒ–çš„æ¨¡å—
- **HiFi-GAN** (vocoder)ï¼šå¯¹éŸ³è´¨å½±å“å¤§
- **Embedding å±‚**ï¼šç»´åº¦é€šå¸¸ä¸å¤§
- **BatchNorm/LayerNorm**ï¼šé‡åŒ–æ”¶ç›Šå°

### âœ… æ¨èé‡åŒ–çš„æ¨¡å—
- **Linear å±‚**ï¼ˆå…¨è¿æ¥ï¼‰ï¼šæ”¶ç›Šæœ€å¤§
- **Attention æ¨¡å—**ï¼šé€Ÿåº¦æå‡æ˜æ˜¾
- **LLM éƒ¨åˆ†**ï¼šå‚æ•°é‡å¤§ï¼Œé€‚åˆé‡åŒ–

### ğŸ” è´¨é‡æ£€æŸ¥
```bash
# ç”Ÿæˆå¯¹æ¯”éŸ³é¢‘
python test_quantized_quality.py

# ä½¿ç”¨ MOS (Mean Opinion Score) è¯„ä¼°
# æˆ–ä½¿ç”¨ ViSQOL å®¢è§‚è¯„ä»·å·¥å…·
```

---

## æ¨èæ–¹æ¡ˆ

### å¼€å‘/æµ‹è¯•ç¯å¢ƒ
```bash
# ä½¿ç”¨ FP16ï¼ˆæœ€ç®€å•ï¼‰
export COSYVOICE_FP16=1
python stream_service.py
```

### ç”Ÿäº§ç¯å¢ƒ
```bash
# 1. é‡åŒ–æ¨¡å‹
python quantize_model.py original_model quantized_model

# 2. æµ‹è¯•è´¨é‡
python benchmark_quantized.py

# 3. éƒ¨ç½²
# ä¿®æ”¹ stream_service.py ä¸­çš„ model_dir æŒ‡å‘é‡åŒ–æ¨¡å‹
```

### æè‡´æ€§èƒ½
```bash
# ä½¿ç”¨ TensorRT (éœ€è¦ NVIDIA GPU)
# å‚è€ƒ runtime/triton_trtllm/ ç›®å½•
cd runtime/triton_trtllm
./run.sh
```

---

## å¸¸è§é—®é¢˜

**Q: é‡åŒ–åéŸ³è´¨ä¸‹é™æ˜æ˜¾ï¼Ÿ**
A: 
1. ä¸è¦é‡åŒ– HiFi-GAN
2. ä½¿ç”¨é™æ€é‡åŒ– + å……è¶³æ ¡å‡†æ•°æ®
3. è€ƒè™‘ä½¿ç”¨ FP16 è€Œé INT8

**Q: CPU ä¸Šé‡åŒ–æ•ˆæœä¸å¥½ï¼Ÿ**
A: INT8 é‡åŒ–ä¸»è¦ä¼˜åŒ– CPUï¼ŒGPU ä¸Šå»ºè®®ç”¨ FP16

**Q: é‡åŒ–åæŠ¥é”™ï¼Ÿ**
A: æŸäº›æ“ä½œä¸æ”¯æŒé‡åŒ–ï¼Œå¯ä»¥ä½¿ç”¨ `QuantStub` å’Œ `DeQuantStub` åŒ…è£¹

**Q: å†…å­˜å ç”¨æ²¡å‡å°‘ï¼Ÿ**
A: åŠ¨æ€é‡åŒ–ä»…å‡å°‘ç£ç›˜å¤§å°ï¼Œè¿è¡Œæ—¶ä»è§£å‹ä¸º FP32ã€‚ä½¿ç”¨é™æ€é‡åŒ–å¯å‡å°‘è¿è¡Œæ—¶å†…å­˜ã€‚
