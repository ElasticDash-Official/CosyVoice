# CosyVoice æ€§èƒ½ä¼˜åŒ–æŒ‡å—

## å·²å®æ–½çš„ä¼˜åŒ–

### 1. æ—¥å¿—ä¼˜åŒ– âœ…
- å°†æ—¥å¿—çº§åˆ«ä» INFO æ”¹ä¸º WARNINGï¼Œå‡å°‘ I/O å¼€é”€
- ç§»é™¤å†—ä½™çš„è¯¦ç»†æ—¥å¿—è¾“å‡º
- ä»…åœ¨é”™è¯¯æ—¶è¾“å‡ºå…³é”®ä¿¡æ¯

### 2. éŸ³é¢‘æ–‡ä»¶å¤„ç†ä¼˜åŒ– âœ…
- **é¢„åŠ è½½æœºåˆ¶**ï¼šå¯åŠ¨æ—¶é¢„åŠ è½½é»˜è®¤éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯ï¼Œé¿å…æ¯æ¬¡è¯·æ±‚éƒ½è¯»å–
- **ç¼“å­˜éªŒè¯**ï¼šé»˜è®¤éŸ³é¢‘åªéªŒè¯ä¸€æ¬¡ï¼Œä¸Šä¼ éŸ³é¢‘å¿«é€ŸéªŒè¯
- **å‡å°‘ I/O**ï¼šç§»é™¤é‡å¤çš„ soundfile éªŒè¯æ£€æŸ¥

### 3. æ•°æ®ç±»å‹ä¼˜åŒ– âœ…
- ç§»é™¤ä¸å¿…è¦çš„ `astype('float32')` è½¬æ¢ï¼ˆnumpyæ•°ç»„é»˜è®¤å·²æ˜¯float32ï¼‰
- ç›´æ¥ä½¿ç”¨ `tobytes()` å‡å°‘å†…å­˜æ‹·è´

### 4. å¹¶å‘é…ç½®ä¼˜åŒ– âœ…
- æé«˜ `limit_concurrency` ä» 10 åˆ° 20
- å¢åŠ  `backlog=2048` æå‡è¿æ¥é˜Ÿåˆ—

### 5. ä»£ç ç®€åŒ– âœ…
- ç§»é™¤é‡å¤çš„å¯¼å…¥è¯­å¥
- ç®€åŒ–æ—¥å¿—è¾“å‡ºé€»è¾‘
- ä¼˜åŒ–é”™è¯¯å¤„ç†æµç¨‹

## è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®

### ğŸš€ æ¨¡å‹çº§åˆ«ä¼˜åŒ–

#### 1. ä½¿ç”¨ TorchScript / ONNX åŠ é€Ÿ
```bash
# å¯¼å‡ºä¸º TorchScript (JIT)
python cosyvoice/bin/export_jit.py

# å¯¼å‡ºä¸º ONNX
python cosyvoice/bin/export_onnx.py
```

#### 2. é‡åŒ–æ¨¡å‹ (å‡å°‘æ¨¡å‹å¤§å°å’Œæ¨ç†æ—¶é—´)
```python
import torch
# åŠ¨æ€é‡åŒ– (8-bit)
quantized_model = torch.quantization.quantize_dynamic(
    cosyvoice.model, {torch.nn.Linear}, dtype=torch.qint8
)
```

#### 3. ä½¿ç”¨ Flash Attention (å¦‚æœæ¨¡å‹æ”¯æŒ)
```bash
pip install flash-attn --no-build-isolation
```

### âš¡ æ¨ç†ä¼˜åŒ–

#### 4. æ‰¹å¤„ç†æ¨ç† (Batch Processing)
ä¿®æ”¹ API æ”¯æŒæ‰¹é‡æ–‡æœ¬ï¼š
```python
@app.post("/synthesize_batch")
async def synthesize_batch(texts: List[str], ...):
    # æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡æœ¬ï¼Œæé«˜GPUåˆ©ç”¨ç‡
    pass
```

#### 5. GPUä¼˜åŒ–
```python
# åœ¨æ¨¡å‹åˆå§‹åŒ–æ—¶è®¾ç½®
torch.backends.cudnn.benchmark = True  # è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç®—æ³•
torch.set_float32_matmul_precision('high')  # TF32ç²¾åº¦åŠ é€Ÿ
```

#### 6. ä½¿ç”¨ Triton/TensorRT åŠ é€Ÿ
å‚è€ƒ `runtime/triton_trtllm/` ç›®å½•çš„é…ç½®

### ğŸ”§ ç³»ç»Ÿçº§åˆ«ä¼˜åŒ–

#### 7. ä½¿ç”¨æ›´å¿«çš„ ASGI æœåŠ¡å™¨
```bash
# æ›¿æ¢ uvicorn ä¸º hypercorn (ä½¿ç”¨uvloop)
pip install hypercorn uvloop

# å¯åŠ¨
hypercorn stream_service:app --bind 0.0.0.0:50000 --workers 1
```

æˆ–è€…å¯ç”¨ uvicorn çš„ uvloopï¼š
```python
uvicorn.run(
    app,
    host="0.0.0.0",
    port=50000,
    loop="uvloop",  # ä½¿ç”¨æ›´å¿«çš„äº‹ä»¶å¾ªç¯
    workers=1
)
```

#### 8. å†…å­˜ç®¡ç†
```python
import torch
import gc

# åœ¨æ¯æ¬¡æ¨ç†åæ¸…ç†ç¼“å­˜
@app.post("/synthesize")
async def synthesize_streaming(...):
    try:
        # ... æ¨ç†ä»£ç  ...
        pass
    finally:
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()
```

#### 9. ä½¿ç”¨ Redis ç¼“å­˜å¸¸ç”¨ç»“æœ
```python
import redis
import hashlib

redis_client = redis.Redis(host='localhost', port=6379, db=0)

def get_cache_key(text, instruction):
    return hashlib.md5(f"{text}_{instruction}".encode()).hexdigest()

# åœ¨æ¨ç†å‰æ£€æŸ¥ç¼“å­˜
cache_key = get_cache_key(text, instruction)
cached = redis_client.get(cache_key)
if cached:
    return cached
```

### ğŸ“Š ç›‘æ§å’Œè°ƒè¯•

#### 10. æ·»åŠ æ€§èƒ½ç›‘æ§
```python
import time
from functools import wraps

def timing_decorator(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start = time.time()
        result = await func(*args, **kwargs)
        logger.warning(f"{func.__name__} took {time.time()-start:.3f}s")
        return result
    return wrapper

@app.post("/synthesize")
@timing_decorator
async def synthesize_streaming(...):
    pass
```

#### 11. ä½¿ç”¨ Prometheus ç›‘æ§
```bash
pip install prometheus-fastapi-instrumentator

# åœ¨ä»£ç ä¸­æ·»åŠ 
from prometheus_fastapi_instrumentator import Instrumentator

Instrumentator().instrument(app).expose(app)
```

## æ€§èƒ½æµ‹è¯•

### åŸºå‡†æµ‹è¯•è„šæœ¬
```bash
# ä½¿ç”¨ ab (Apache Bench)
ab -n 100 -c 10 -p request.json -T application/json http://localhost:50000/synthesize

# ä½¿ç”¨ wrk
wrk -t4 -c10 -d30s --latency http://localhost:50000/synthesize
```

### é¢„æœŸæ€§èƒ½æå‡
- **æ—¥å¿—ä¼˜åŒ–**: ~5-10% å»¶è¿Ÿå‡å°‘
- **éŸ³é¢‘ç¼“å­˜**: ~10-15% é¦–æ¬¡è¯·æ±‚åŠ é€Ÿ
- **å¹¶å‘æå‡**: æ”¯æŒæ›´å¤šå¹¶å‘è¯·æ±‚
- **æ¨¡å‹é‡åŒ–**: ~2-3x æ¨ç†åŠ é€Ÿï¼ˆè½»å¾®è´¨é‡æŸå¤±ï¼‰
- **TensorRT**: ~3-5x æ¨ç†åŠ é€Ÿ
- **uvloop**: ~10-20% ç½‘ç»œæ€§èƒ½æå‡

## ç¡¬ä»¶å»ºè®®

### GPU ä¼˜åŒ–
- ä½¿ç”¨ NVIDIA GPU with Tensor Cores (RTX ç³»åˆ—ã€A100ç­‰)
- è‡³å°‘ 8GB VRAM
- CUDA 11.8+ å’Œæœ€æ–°é©±åŠ¨

### CPU ä¼˜åŒ–
- ä½¿ç”¨æ”¯æŒ AVX2/AVX512 çš„ CPU
- è‡³å°‘ 4 æ ¸å¿ƒ
- 16GB+ RAM

### ç½‘ç»œä¼˜åŒ–
- ä½¿ç”¨ HTTP/2 (FastAPI é»˜è®¤æ”¯æŒ)
- å¯ç”¨ gzip å‹ç¼©
- è€ƒè™‘ä½¿ç”¨ CDN åˆ†å‘

## æ•…éšœæ’æŸ¥

### å¦‚æœè¿˜æ˜¯æ…¢
1. **æ£€æŸ¥ GPU åˆ©ç”¨ç‡**: `nvidia-smi`
2. **æ£€æŸ¥å†…å­˜**: `htop` æˆ– `free -h`
3. **æ£€æŸ¥ç£ç›˜ I/O**: `iotop`
4. **æ£€æŸ¥ç½‘ç»œ**: `iftop`
5. **åˆ†æç“¶é¢ˆ**: ä½¿ç”¨ `py-spy` æˆ– `cProfile`

```bash
# ä½¿ç”¨ py-spy åˆ†æ
pip install py-spy
py-spy top --pid <process_id>
```

## æ€»ç»“

**ä½æˆæœ¬ä¼˜åŒ–** (å·²å®Œæˆ):
- âœ… æ—¥å¿—çº§åˆ«è°ƒæ•´
- âœ… éŸ³é¢‘æ–‡ä»¶é¢„åŠ è½½
- âœ… å‡å°‘é‡å¤éªŒè¯
- âœ… ä»£ç ç®€åŒ–

**ä¸­ç­‰æˆæœ¬ä¼˜åŒ–** (æ¨è):
- ğŸ”¸ ä½¿ç”¨ uvloop
- ğŸ”¸ å¯ç”¨ TorchScript
- ğŸ”¸ GPU åç«¯ä¼˜åŒ–

**é«˜æˆæœ¬ä¼˜åŒ–** (ç”Ÿäº§ç¯å¢ƒ):
- ğŸ”¹ æ¨¡å‹é‡åŒ–
- ğŸ”¹ TensorRT åŠ é€Ÿ
- ğŸ”¹ è´Ÿè½½å‡è¡¡ + å¤šå®ä¾‹
