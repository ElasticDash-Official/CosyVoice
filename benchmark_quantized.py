#!/usr/bin/env python3
"""
æ€§èƒ½æµ‹è¯•å·¥å…·ï¼šå¯¹æ¯”åŸå§‹æ¨¡å‹å’Œé‡åŒ–æ¨¡å‹çš„æ€§èƒ½
"""

import torch
import time
import sys
import os
from cosyvoice.cli.cosyvoice import AutoModel

def benchmark_model(model_dir, test_text, iterations=5, use_fp16=False):
    """
    æµ‹è¯•æ¨¡å‹æ€§èƒ½
    
    Args:
        model_dir: æ¨¡å‹ç›®å½•
        test_text: æµ‹è¯•æ–‡æœ¬
        iterations: æµ‹è¯•æ¬¡æ•°
        use_fp16: æ˜¯å¦ä½¿ç”¨ FP16
    """
    print(f"\n{'='*60}")
    print(f"Testing: {os.path.basename(model_dir)}")
    print(f"FP16: {use_fp16}")
    print(f"{'='*60}")
    
    # åŠ è½½æ¨¡å‹
    print("Loading model...")
    start_load = time.time()
    cosyvoice = AutoModel(model_dir=model_dir, fp16=use_fp16)
    load_time = time.time() - start_load
    print(f"âœ“ Model loaded in {load_time:.2f}s")
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    prompt_wav = "/home/ec2-user/CosyVoice/asset/zero_shot_prompt.wav"
    if not os.path.exists(prompt_wav):
        # å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
        prompt_wav = os.path.join(os.path.dirname(model_dir), "asset/zero_shot_prompt.wav")
        if not os.path.exists(prompt_wav):
            print(f"âš ï¸  Warning: prompt_wav not found, using model's default")
            prompt_wav = None
    
    prompt_text = "å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚"
    
    # é¢„çƒ­ï¼ˆé¿å…é¦–æ¬¡æ¨ç†çš„åˆå§‹åŒ–å¼€é”€ï¼‰
    print("Warming up...")
    if prompt_wav:
        for _ in cosyvoice.inference_zero_shot(test_text[:20], prompt_text, prompt_wav, stream=False):
            pass
    
    # æ­£å¼æµ‹è¯•
    print(f"Running {iterations} iterations...")
    times = []
    audio_lengths = []
    
    for i in range(iterations):
        start = time.time()
        
        audio_chunks = []
        if prompt_wav:
            for result in cosyvoice.inference_zero_shot(test_text, prompt_text, prompt_wav, stream=False):
                audio_chunks.append(result['tts_speech'])
        
        elapsed = time.time() - start
        times.append(elapsed)
        
        # è®¡ç®—ç”Ÿæˆçš„éŸ³é¢‘é•¿åº¦
        if audio_chunks:
            total_samples = sum(chunk.shape[-1] for chunk in audio_chunks)
            audio_length = total_samples / cosyvoice.sample_rate
            audio_lengths.append(audio_length)
        
        print(f"  Iteration {i+1}/{iterations}: {elapsed:.3f}s", end='')
        if audio_lengths:
            rtf = elapsed / audio_lengths[-1]
            print(f" (RTF: {rtf:.3f})", end='')
        print()
    
    # ç»Ÿè®¡ç»“æœ
    avg_time = sum(times) / len(times)
    min_time = min(times)
    max_time = max(times)
    
    if audio_lengths:
        avg_audio_len = sum(audio_lengths) / len(audio_lengths)
        avg_rtf = avg_time / avg_audio_len
    else:
        avg_audio_len = 0
        avg_rtf = 0
    
    print(f"\n{'='*60}")
    print(f"Results:")
    print(f"{'='*60}")
    print(f"Average time:     {avg_time:.3f}s")
    print(f"Min time:         {min_time:.3f}s")
    print(f"Max time:         {max_time:.3f}s")
    if avg_audio_len > 0:
        print(f"Audio length:     {avg_audio_len:.2f}s")
        print(f"RTF (Real-Time Factor): {avg_rtf:.3f}")
        print(f"  â†’ {'âœ“ Faster than real-time' if avg_rtf < 1 else 'âœ— Slower than real-time'}")
    print(f"{'='*60}")
    
    return {
        'load_time': load_time,
        'avg_time': avg_time,
        'min_time': min_time,
        'max_time': max_time,
        'avg_rtf': avg_rtf,
        'audio_length': avg_audio_len
    }

def compare_models(original_dir, quantized_dir, test_text, iterations=5):
    """å¯¹æ¯”åŸå§‹æ¨¡å‹å’Œé‡åŒ–æ¨¡å‹"""
    
    print("\n" + "ğŸ”¥"*30)
    print("CosyVoice Performance Benchmark")
    print("ğŸ”¥"*30)
    print(f"\nTest text: {test_text}")
    print(f"Iterations: {iterations}")
    
    # æµ‹è¯•åŸå§‹æ¨¡å‹
    try:
        results_original = benchmark_model(original_dir, test_text, iterations, use_fp16=False)
    except Exception as e:
        print(f"âŒ Error testing original model: {e}")
        results_original = None
    
    # æµ‹è¯•é‡åŒ–æ¨¡å‹
    try:
        results_quantized = benchmark_model(quantized_dir, test_text, iterations, use_fp16=True)
    except Exception as e:
        print(f"âŒ Error testing quantized model: {e}")
        results_quantized = None
    
    # å¯¹æ¯”ç»“æœ
    if results_original and results_quantized:
        print("\n" + "="*60)
        print("ğŸ“Š COMPARISON SUMMARY")
        print("="*60)
        
        speedup = results_original['avg_time'] / results_quantized['avg_time']
        load_speedup = results_original['load_time'] / results_quantized['load_time']
        
        print(f"\n{'Metric':<25} {'Original':<15} {'Quantized':<15} {'Improvement':<15}")
        print("-"*70)
        print(f"{'Load time':<25} {results_original['load_time']:>10.2f}s    {results_quantized['load_time']:>10.2f}s    {load_speedup:>10.2f}x")
        print(f"{'Inference time':<25} {results_original['avg_time']:>10.3f}s    {results_quantized['avg_time']:>10.3f}s    {speedup:>10.2f}x")
        print(f"{'RTF':<25} {results_original['avg_rtf']:>10.3f}     {results_quantized['avg_rtf']:>10.3f}     {results_original['avg_rtf']/results_quantized['avg_rtf']:>10.2f}x")
        print("-"*70)
        
        if speedup >= 1.5:
            emoji = "ğŸš€ğŸš€ğŸš€"
        elif speedup >= 1.2:
            emoji = "ğŸš€ğŸš€"
        elif speedup >= 1.0:
            emoji = "ğŸš€"
        else:
            emoji = "âš ï¸"
        
        print(f"\n{emoji} Overall speedup: {speedup:.2f}x {emoji}")
        
        if speedup >= 1.5:
            print("âœ… Excellent! Quantization provides significant speedup.")
        elif speedup >= 1.2:
            print("ğŸ‘ Good speedup from quantization.")
        elif speedup >= 1.0:
            print("ğŸ“Š Modest improvement. Consider other optimizations.")
        else:
            print("âš ï¸  Quantized model is slower. Check configuration.")
        
        print("="*60)

def main():
    if len(sys.argv) < 3:
        print("Usage: python benchmark_quantized.py <original_model_dir> <quantized_model_dir> [test_text]")
        print("\nExample:")
        print("  python benchmark_quantized.py \\")
        print("    /home/ec2-user/CosyVoice/pretrained_models/CosyVoice2-0.5B \\")
        print("    /home/ec2-user/CosyVoice/pretrained_models/CosyVoice2-0.5B-quantized \\")
        print('    "ä½ å¥½ï¼Œæ¬¢è¿æ¥åˆ°æˆ‘ä»¬çš„é¤å…ã€‚"')
        sys.exit(1)
    
    original_dir = sys.argv[1]
    quantized_dir = sys.argv[2]
    test_text = sys.argv[3] if len(sys.argv) > 3 else "ä½ å¥½ï¼Œæ¬¢è¿å…‰ä¸´æˆ‘ä»¬çš„é¤å…ï¼Œä»Šå¤©æƒ³åƒç‚¹ä»€ä¹ˆå‘¢ï¼Ÿ"
    
    # éªŒè¯è·¯å¾„
    if not os.path.exists(original_dir):
        print(f"âŒ Error: Original model directory not found: {original_dir}")
        sys.exit(1)
    
    if not os.path.exists(quantized_dir):
        print(f"âŒ Error: Quantized model directory not found: {quantized_dir}")
        sys.exit(1)
    
    # è¿è¡Œå¯¹æ¯”
    compare_models(original_dir, quantized_dir, test_text, iterations=5)

if __name__ == "__main__":
    main()
